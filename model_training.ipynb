{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: lightgbm in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (from lightgbm) (2.3.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (from lightgbm) (1.16.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install lightgbm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (2.3.4)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (1.7.2)\n",
            "Requirement already satisfied: lightgbm in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (4.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn lightgbm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pip in c:\\users\\udani\\appdata\\roaming\\python\\python312\\site-packages (25.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, f1_score, recall_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Udani\\AppData\\Local\\Temp\\ipykernel_1432\\1770539240.py:2: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"Dementia Prediction Dataset.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loading and preparation successful!\n",
            "\n",
            "Final features being used for the model:\n",
            "['SEX', 'EDUC', 'RACE', 'MARISTAT', 'INDEPEND', 'RESIDENC', 'Age']\n",
            "\n",
            "Distribution of Dementia in the training set:\n",
            "DementiaStatus\n",
            "0    0.704962\n",
            "1    0.295038\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Shape of training features: (156156, 7)\n",
            "Shape of testing features: (39040, 7)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Dementia Prediction Dataset.csv\")\n",
        "\n",
        "# --- 1. Create the Binary Target Variable ---\n",
        "df['DementiaStatus'] = df['NACCUDSD'].apply(lambda x: 1 if x == 4 else 0)\n",
        "\n",
        "\n",
        "# --- 2. Define the list of non-medical features to use ---\n",
        "non_medical_features = [\n",
        "    'VISITYR',\n",
        "    'BIRTHYR',\n",
        "    'SEX',\n",
        "    'EDUC',\n",
        "    'RACE',\n",
        "    'MARISTAT',\n",
        "    'INDEPEND',\n",
        "    'RESIDENC'\n",
        "]\n",
        "\n",
        "# 3. Create the 'Age' Feature and Finalize Feature Set 'X' \n",
        "# Select only the columns we need\n",
        "X = df[non_medical_features].copy()\n",
        "\n",
        "# Engineer the 'Age' feature\n",
        "X['Age'] = X['VISITYR'] - X['BIRTHYR']\n",
        "\n",
        "# Drop the original year columns as 'Age' is now the primary feature\n",
        "X = X.drop(['VISITYR', 'BIRTHYR'], axis=1)\n",
        "\n",
        "\n",
        "#  4. Define the Final Target Variable 'y' \n",
        "y = df['DementiaStatus']\n",
        "\n",
        "\n",
        "#  5. Perform the Train-Test Split \n",
        "# This will now work correctly. We stratify on 'y' because the dataset is imbalanced.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# 6. Verification \n",
        "print(\"Data loading and preparation successful!\")\n",
        "print(\"\\nFinal features being used for the model:\")\n",
        "print(X_train.columns.tolist())\n",
        "\n",
        "print(\"\\nDistribution of Dementia in the training set:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nShape of training features:\", X_train.shape)\n",
        "print(\"Shape of testing features:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training Logistic Regression ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93     27522\n",
            "           1       0.81      0.85      0.83     11518\n",
            "\n",
            "    accuracy                           0.90     39040\n",
            "   macro avg       0.87      0.88      0.88     39040\n",
            "weighted avg       0.90      0.90      0.90     39040\n",
            "\n",
            "AUC-ROC = 0.914\n",
            "\n",
            "--- Training Random Forest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.92     27522\n",
            "           1       0.83      0.80      0.82     11518\n",
            "\n",
            "    accuracy                           0.89     39040\n",
            "   macro avg       0.87      0.87      0.87     39040\n",
            "weighted avg       0.89      0.89      0.89     39040\n",
            "\n",
            "AUC-ROC = 0.912\n",
            "\n",
            "--- Training LightGBM ---\n",
            "[LightGBM] [Info] Number of positive: 46072, number of negative: 110084\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008598 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 178\n",
            "[LightGBM] [Info] Number of data points in the train set: 156156, number of used features: 28\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.295038 -> initscore=-0.871038\n",
            "[LightGBM] [Info] Start training from score -0.871038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Udani\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\Udani\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.93     27522\n",
            "           1       0.82      0.84      0.83     11518\n",
            "\n",
            "    accuracy                           0.90     39040\n",
            "   macro avg       0.88      0.88      0.88     39040\n",
            "weighted avg       0.90      0.90      0.90     39040\n",
            "\n",
            "AUC-ROC = 0.924\n"
          ]
        }
      ],
      "source": [
        "# Define the models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Loop through each model\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Training {name} ---\")\n",
        "    \n",
        "    # Create a full pipeline that first preprocesses the data and then runs the model\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', model)])\n",
        "    \n",
        "    # Train the pipeline on the raw training data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on the raw test data\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate and store metrics\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    results[name] = {\"AUC-ROC\": auc, \"F1-Score\": f1, \"Recall\": recall}\n",
        "\n",
        "    # Print results for the current model\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"AUC-ROC = {auc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Final Model Comparison ---\n",
            "                      AUC-ROC  F1-Score    Recall\n",
            "LightGBM             0.923678  0.830983  0.839208\n",
            "Logistic Regression  0.914094  0.829891  0.849453\n",
            "Random Forest        0.911915  0.815328  0.802657\n"
          ]
        }
      ],
      "source": [
        "# --- 4. Final Comparison Table ---\n",
        "results_df = pd.DataFrame(results).T.sort_values(by=\"AUC-ROC\", ascending=False)\n",
        "print(\"\\n--- Final Model Comparison ---\")\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
